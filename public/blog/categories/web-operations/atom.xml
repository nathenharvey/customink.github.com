<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: web operations | EngineerInk]]></title>
  <link href="http://technology.customink.com/blog/categories/web-operations/atom.xml" rel="self"/>
  <link href="http://technology.customink.com/"/>
  <updated>2012-05-24T16:36:40-04:00</updated>
  <id>http://technology.customink.com/</id>
  <author>
    <name><![CDATA[CustomInk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[PagerDuty, Nagios and Chef]]></title>
    <link href="http://technology.customink.com/blog/2012/01/31/pagerduty/"/>
    <updated>2012-01-31T10:14:00-05:00</updated>
    <id>http://technology.customink.com/blog/2012/01/31/pagerduty</id>
    <content type="html"><![CDATA[<h2>Three Things that Work Great Together</h2>

<p>If you use Chef and Nagios, you already know what a great combination they make.  As you build new servers they automatically start getting monitored by Nagios.  Without you having to do anything they're grouped together based on role, so its easy to apply the same checks for all servers in a given role.  If you haven't tried Nagios built with the chef cookbook its easy to get started with this <a href="http://wiki.opscode.com/display/chef/Nagios+Quick+Start">guide</a> from Opscode.</p>

<p><a href="http://www.pagerduty.com/]">PagerDuty</a> is a service that manages your on-call alerting and escalation policies.  Its hard to love a service that wakes you up in the middle of the night telling you about problems with your servers (my wife is really not a fan), but PagerDuty is helpful.  We generally set it to send an email about a problem first, then send an SMS text and finally to actually make a phone call if no one has responded.  It will go through a rotating list of people on call and accepts alerts from a number of monitoring services including Nagios and AlertSite.</p>

<p>Opscode recently accepted my addition of a PagerDuty recipe to the <a href="https://github.com/opscode/cookbooks/tree/master/nagios">Nagios cookbook</a> which makes it incredibly easy to connect your Nagios instance to PagerDuty.  You just add a PagerDuty API key as an attribute, apply the pagerduty recipe to your nagios server (see their <a href="http://www.pagerduty.com/docs/guides/nagios-integration-guide">guide</a> for instructions on getting your key) and you're good to go.</p>

<p>If you add the API key(s) to your Chef environments, you can tie each environment to a different escalation policy.  That way your staging environments just send email alerts while production actually texts and calls.</p>

<p>One of the big wins of using the Nagios plugins is that if a service recovers the PagerDuty incident gets resolved automatically so it doesn't continue to escalate the problem.  Also if you acknowledge a problem in Nagios the acknowledgment flows through to PagerDuty.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why we chose Chef over Puppet at CustomInk]]></title>
    <link href="http://technology.customink.com/blog/2011/11/21/why-we-chose-chef-over-puppet-at-customink/"/>
    <updated>2011-11-21T03:29:00-05:00</updated>
    <id>http://technology.customink.com/blog/2011/11/21/why-we-chose-chef-over-puppet-at-customink</id>
    <content type="html"><![CDATA[<p>Not unlike most technology choices, the choice of which configuration management tool to use for managing your infrastructure as code is sure to spark debate among opinionated technologists. There are certainly a number of choices available all of which have their own strengths and weaknesses. There are a number of things to consider as you select a tool.</p>

<p>Before we get into any of the specifics, I want to make it clear that the "right" answer to this question is a simple, but emphatic "yes!" Yes, you should be using a tool that allows you to manage your infrastructure as code. That tool should NOT be a server.txt file that you keep on the machine that documents the installation, set-up, and configuration changes you've made. Moving that text to somewhere other than the local server is a step in the right direction but isn't really the answer. Moving the server.txt file to your corporate wiki is going to suck just as bad.</p>

<p>I think Mark Imbriaco summed it up quite nicely in 140 characters or less:</p>

<p>{% blockquote @markimbriaco https://twitter.com/markimbriaco/statuses/89180299824599041 %}
Pro-tip: Nobody gives a shit about your opinion of Chef vs. Puppet. Seriously. Just fucking stop it already. #usewhatworksforyou
{% endblockquote %}</p>

<p>As you consider which tool is right for you, you'll need to consider a number of questions. I think of these as the WIIFs, or "what's in it for..." questions:</p>

<!--more-->


<h3>WIIFM - What's in it for me</h3>

<p>You're going to want a tool that you're happy working with. You're going to make an investment in this tool. You'll need to learn to be proficient with the tool, master it, and use it in your everyday workflow. Pick something that you'll be happy working with for some time.</p>

<h3>WIIFC - What's in it for my customers</h3>

<p>It's highly unlikely that your customers know or care anything about how your infrastructure was built, provisioned, and managed. Why should they have any say about which tool you pick? Your customers are keenly interested in the services or products you offer. They also care about things like performance, availability, and how quickly you recover from an issue or outage. If they don't care about these things, they'll likely not be your customers for long. As you grow your business, you'll want to have more time for delivering value to customers. Spend less time building, provisioning, upgrading, and repairing your infrastructure.</p>

<h3>WIIFB - What's in it for my business</h3>

<p>You may be the only one who has to build and manage the infrastructure in your company but it's likely you'll eventually move beyond a technology team of one. As your technology team grows, you'll want to include everyone in the process of managing your infrastructure. This includes the people you might not think of as typically having a say in the infrastructure: developers, quality assurance engineers, etc. You do not want to be the only person in your company who knows how to manage the infrastructure and use the tools you've selected. Sure, it gives you a false sense of job security and feeds into your hero-complex but you need to be able to pass the on-call baton to someone else. Cost may also be a factor to consider when selecting a solution although it's likely it's more of a data-point than selection criteria, given the solutions that are on the market.</p>

<p>I cannot tell you which tool is right for you. There are many factors including the ones I've listed above. I have some experience with both Puppet and Chef. At <a href="http://www.customink.com">CustomInk</a>, we decided to switch to Chef after using Puppet for about two years.</p>

<h2>Why did we switch?</h2>

<h3>We're a Rails shop</h3>

<p>CustomInk is a Ruby on Rails shop and has been for many years. Being a Rails shop helped push us towards Chef in two ways. As a Rails shop, we suffer a bit from from the stereotypical "newer and shinier is better" syndrome that many people feel ails the Rails community. As a Rails shop, the domain-specific language (DSL) of Chef is a more comfortable way for us to work. Everyone on the technology team can easily understand the code.</p>

<h3>We started with Puppet</h3>

<p>We started with Puppet so, naturally, that's the one we switched from. Puppet was, and actually still is, working well for us. However, we found that working in Puppet was going a bit slower than we'd like. Also, as we started learning more about Chef we started to see how we'd be able to quickly benefit from some of the features it offers. To be fair, we were comparing the Puppet we were using (0.24.x) to the latest (at the time) version of Chef (0.9.x). There may well have been ways to do the things we wanted with Puppet but we weren't. Chef was intriguing and it looked like we'd be able to get more from it. Instead of working to refactor our Puppet and get smarter with how to use it, we went with Chef.</p>

<h3>Search</h3>

<p>Chef's ability to search our environment and use that information at run time is very appealing. The ability for us to define a database.yml template that can have the "host" value populated at runtime based on which host is currently the primary database server is great. Using search in our capistrano recipes to determine where the code should be deployed is a huge win.</p>

<h3>Knife</h3>

<p>Knife is Chef's powerful command line interface. There are many things you can do with knife, most of which fall outside of the scope of this article. Knife allows you to interact with your entire infrastructure and Chef code base. Use knife to bootstrap a server, build the scaffolding for a new cookbook, or apply a role to a set of nodes in your environment. You can use knife ssh to execute commands on any number of nodes in your environment. knife ssh + search is a very powerful combination. "Run this command on all nodes with role X."</p>

<h3>Dependency Management</h3>

<p>We found that defining dependencies in Puppet was overly verbose and cumbersome. With Chef, order matters and we could rest assured that dependencies would be met if we specified them in the proper order.</p>

<h3>Strong Community</h3>

<p>OpsCode has done a great job of keeping up a strong community. The community.opscode.com site, where hundreds of cookbooks are shared, is a great way to get started. OpsCode has also hosted numerous webinars, publishes all of their training material, and makes it very easy to contribute patches. Frankly, I don't have any experience with this in the Puppet world. However, my lack of experience with this in the Puppet world is likely attributed simply to the way my development habits have changed over time. At CustomInk, we've been able to submit patches to chef, a number of cookbooks, and have also published some of our own cookbooks.</p>

<h3>Developer Happiness</h3>

<p>As I mentioned previously, the DSL with Chef is much more comfortable than that of Puppet. The mental model and workflow suit us. I find that the time I spend working in Chef is when I feel most productive and happy.</p>

<p>I often wonder if the reason Chef is the right tool is because it's the second one we've used. Coming to infrastructure as code includes a learning curve. I feel that we're better Chef developers because we learned from our experience with Puppet. Some may even agree that Chef's a better tool because the developers of Chef learned from their experience with Puppet.</p>

<h3>A note for projects that are just getting started</h3>

<p>If your project is just getting started, the best choice for you is probably not to use any of the configuration management tools that allow you to manage your infrastructure as code. You should stay focused exclusively on delivering value to your customers. It's likely that the best solution for you is <a href="http://www.heroku.com/">Heroku</a>. Sure, Heroku puts some constraints on how you build your app, but they're a good way for you to think creatively. You can, and should, delay your choice of tools until you're ready to spin up your first server.</p>

<h2>TL;DR</h2>

<ul>
<li>If the question is "Chef or Puppet?", the answer is "Yes." You need to manage you infrastructure as code</li>
<li>Search, knife, dependency management, community, and developer happiness were the key reasons we switched</li>
<li>Chef is the right tool for us and it might be the right one for you</li>
<li>If you're new to the idea of "Infrastructure as Code", understand that there's a learning curve but your efforts will be rewarded</li>
</ul>


<p>Did you have to make a similar choice? What were some of the deciding factors? Which tool or framework did you end up with?</p>

<hr />

<p><sub>Reposted from <a href="http://nathenharvey.com/blog/2011/11/21/why-we-chose-chef-over-puppet-at-customink/">Nathen Harvey's blog</a>.</sub></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing mod_rewrite and apache redirects]]></title>
    <link href="http://technology.customink.com/blog/2010/07/16/testing-mod-rewrite-and-apache-redirects/"/>
    <updated>2010-07-16T09:00:00-04:00</updated>
    <id>http://technology.customink.com/blog/2010/07/16/testing-mod-rewrite-and-apache-redirects</id>
    <content type="html"><![CDATA[<p>At <a href="http://www.customink.com">CustomInk</a>, we recently migrated from mongrel to Passenger for our Ruby on Rails website. This migration included a full rewrite of our apache configuration files.</p>

<p>With over 500 redirect and rewrite rules in place I needed a way to ensure my copy-n-paste skills were up to snuff and that we didn't loose any redirects along the way.</p>

<p>In my search for help, I found a <a href="http://www.viget.com/extend/test-drive-mod-rewrite-rules-with-testunit/">blog post by Patrick Reagan from Viget labs</a> that described a method for writing tests that will verify all the rewrite rules and redirects. Patrick's ideas were packaged up into a gem and available on <a href="http://github.com/eightbitraptor/http_redirect_test">github</a>.</p>

<p>I can now write up tests like:</p>

<p><code>ruby
should_redirect "/cink/ideas/ideas.jsp", :to =&gt; "/inspiration/"
</code></p>

<p>So now I can to some TDC (test-driven configuration) whenever I get a request for a new redirect.</p>

<p>What other methods have you used to test your rewrite rules?</p>

<hr />

<p><sub>Reposted from <a href="http://nathenharvey.com/blog/2010/07/16/testing-mod-rewrite-and-apache-redirects/">Nathen Harvey's blog</a>.</sub></p>
]]></content>
  </entry>
  
</feed>
